{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    " \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import argparse\n",
    "import os\n",
    "import cv2 \n",
    "import random\n",
    "import sys\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"./finaldata\" \n",
    "CATEGORIES = [\"Boring\", \"Interesting\"]\n",
    "training_data = []\n",
    "feature_extraction_data = []\n",
    "IMG_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stitch the images together \n",
    "## 0 1 2 \n",
    "## 3 4 5\n",
    "## 6 7 8\n",
    "\n",
    "def stitch_images(file_path, file_name):\n",
    "    images = [Image.open(image) for image in [file_path + \"/\" + file_name + str(x) + \".png\" for x in range(100, 109)]]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = int(sum(widths) / 3)\n",
    "    total_height = int(sum(heights) / 3)\n",
    "    new_image = Image.new(\"RGB\", (total_width, total_height))\n",
    "    for index in range(0, 9):\n",
    "        image = images[index]\n",
    "        new_image.paste(image, ((index % 3) * image.size[0], math.floor(index / 3) * image.size[1]))\n",
    "    if not os.path.isdir(file_path + \"/combined/\"):\n",
    "        os.mkdir(file_path + \"/combined/\")\n",
    "    IMAGE_DIR = os.path.join(file_path, \"combined/\") + file_name + \"combined.png\"\n",
    "    new_image.save(IMAGE_DIR)\n",
    "    return IMAGE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES: \n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for image in sorted(os.listdir(path)): \n",
    "            if \"100\" not in image or \"combined\" in image: ## Find the starting frame\n",
    "                continue\n",
    "            IMAGE_DIR = stitch_images(path, image[0:-7])\n",
    "            try: \n",
    "                img_array = cv2.imread(IMAGE_DIR, cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                # print(new_array.shape[0], new_array.shape[1])\n",
    "                feature = np.reshape(new_array, (new_array.shape[0] * new_array.shape[1]))\n",
    "                training_data.append([new_array, class_num])\n",
    "                if class_num == 0:\n",
    "                    feature_extraction_data.append([feature, False])\n",
    "                else: \n",
    "                    feature_extraction_data.append([feature, True])\n",
    "            except Exception as e: \n",
    "                pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(feature_extraction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = open(\"file.csv\", \"ab\")\n",
    "feature_data = []\n",
    "for i in range(len(feature_extraction_data)): \n",
    "    row_data = np.append(feature_extraction_data[i][0], feature_extraction_data[i][1])\n",
    "    feature_data = np.append(feature_data, row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data.reshape(4318, 40001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"file.csv\", feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
