{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import argparse\n",
    "import os\n",
    "import cv2 \n",
    "import random\n",
    "\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "import pickle\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/Users/liaoqt/documents/CS294/data\"\n",
    "CATEGORIES = [\"Boring\", \"Interesting\"]\n",
    "training_data = []\n",
    "feature_extraction_data = []\n",
    "IMG_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stitch the images together \n",
    "## 0 1 2 \n",
    "## 3 4 5\n",
    "## 6 7 8\n",
    "\n",
    "def stitch_images(file_path, file_name):\n",
    "    images = [Image.open(image) for image in [file_path + \"/\" + file_name + str(x) + \".png\" for x in range(100, 109)]]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = int(sum(widths) / 3)\n",
    "    total_height = int(sum(heights) / 3)\n",
    "    new_image = Image.new(\"RGB\", (total_width, total_height))\n",
    "    for index in range(0, 9):\n",
    "        image = images[index]\n",
    "        new_image.paste(image, ((index % 3) * image.size[0], math.floor(index / 3) * image.size[1]))\n",
    "\n",
    "    IMAGE_DIR = os.path.join(file_path, \"combined/\") + file_name + \"combined.png\"\n",
    "    new_image.save(IMAGE_DIR)\n",
    "    return IMAGE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for category in CATEGORIES: \n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for image in sorted(os.listdir(path)): \n",
    "            if \"100\" not in image: ## Find the starting frame\n",
    "                continue\n",
    "            IMAGE_DIR = stitch_images(path, image[0:-7])\n",
    "            try: \n",
    "                img_array = cv2.imread(IMAGE_DIR, cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "                if class_num == 0:\n",
    "                    feature_extraction_data.append([IMAGE_DIR, False])\n",
    "                else: \n",
    "                    feature_extraction_data.append([IMAGE_DIR, True])\n",
    "                \n",
    "            except Exception as e: \n",
    "                pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(feature_extraction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, labels = [], []\n",
    "for image_path, label in feature_extraction_data: \n",
    "    image_paths.append(image_path)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "def compute_entropy(signal):\n",
    "    lensig = signal.size\n",
    "    symset = list(set(signal))\n",
    "    numsym = len(symset)\n",
    "    propab = [np.size(signal[signal == i]) / (1.0 * lensig) for i in symset]\n",
    "    entropy = np.sum([p * np.log2(1.0 / p) for p in propab])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropys = []\n",
    "# for i in range(len(image_paths)): \n",
    "image = np.array(Image.open(image_paths[0]).convert(\"L\"))\n",
    "N = 5\n",
    "S = image.shape\n",
    "entropy = 0.0\n",
    "for row in range(S[0]):\n",
    "    for col in range(S[1]):\n",
    "        Lx = max(0, col - N)\n",
    "        Ux = min(S[1], col + N)\n",
    "        Ly = max(0, row - N)\n",
    "        Uy = min(S[0], row + N)\n",
    "        region = image[Ly: Uy, Lx : Ux].flatten()\n",
    "        entropy += compute_entropy(region)\n",
    "entropys.append([entropy, labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pretrainedmodels\n",
    "import pretrainedmodels.utils as utils\n",
    "import codecs\n",
    "import sys\n",
    "\n",
    "model_name = 'nasnetalarge'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "model.eval()\n",
    "\n",
    "load_img = utils.LoadImage()\n",
    "tf_img = utils.TransformImage(model)\n",
    "features_file = open(\"file.csv\", \"ab\")\n",
    "feature_data = []\n",
    "\n",
    "for i in range(len(image_paths)):\n",
    "        input_img = load_img(image_paths[i])\n",
    "        input_tensor = tf_img(input_img)\n",
    "        input_tensor = input_tensor.unsqueeze(0)\n",
    "        input = torch.autograd.Variable(input_tensor, requires_grad=False)\n",
    "        output_logits = model(input)\n",
    "        output_features = model.features(input)\n",
    "        output_logits = model.logits(output_features)\n",
    "        output_logits = output_logits[0].detach().numpy()\n",
    "        row_data = np.append(output_logits, labels[i])\n",
    "        feature_data = np.append(feature_data, row_data)\n",
    "        \n",
    "#         np.savetxt(\"file.csv\", output_logits[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = feature_data.reshape(44, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-58814885245b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"file.csv\", feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_features import image_features\n",
    "n = len(image_paths)\n",
    "X_train = image_features(image_paths[:n], progress=True)\n",
    "y_train = no_layer[:n]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for features, label in training_data: \n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 9s 457ms/step - loss: 1.0640 - accuracy: 0.5128\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 9s 451ms/step - loss: 0.6918 - accuracy: 0.5641\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 490ms/step - loss: 0.6902 - accuracy: 0.5641\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 9s 448ms/step - loss: 0.6907 - accuracy: 0.5641\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 9s 452ms/step - loss: 0.6891 - accuracy: 0.5641\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 9s 456ms/step - loss: 0.6912 - accuracy: 0.5641\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 0.6868 - accuracy: 0.5641\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 9s 446ms/step - loss: 0.6843 - accuracy: 0.5641\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 0.6846 - accuracy: 0.5641\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 9s 451ms/step - loss: 0.6891 - accuracy: 0.5641\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 9s 454ms/step - loss: 0.6912 - accuracy: 0.5641\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 9s 449ms/step - loss: 0.6895 - accuracy: 0.5641\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 9s 451ms/step - loss: 0.6844 - accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.6893 - accuracy: 0.5641\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 0.6821 - accuracy: 0.5641\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 0.6828 - accuracy: 0.5641\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.6899 - accuracy: 0.5641\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 9s 466ms/step - loss: 0.6884 - accuracy: 0.5641\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 9s 461ms/step - loss: 0.6872 - accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 9s 463ms/step - loss: 0.6849 - accuracy: 0.5641\n",
      "Accuracy on test---\n",
      "WARNING:tensorflow:From <ipython-input-20-52d71d58b1e8>:43: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "0.4\n",
      "0.0\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 1.1720 - accuracy: 0.4872\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 0.6938 - accuracy: 0.5385\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 477ms/step - loss: 0.6922 - accuracy: 0.5641\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 0.6917 - accuracy: 0.5641\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 9s 446ms/step - loss: 0.6912 - accuracy: 0.5641\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.6888 - accuracy: 0.5641\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 9s 457ms/step - loss: 0.6890 - accuracy: 0.5641\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 10s 487ms/step - loss: 0.6895 - accuracy: 0.5641\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 9s 467ms/step - loss: 0.6884 - accuracy: 0.5641\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 9s 454ms/step - loss: 0.6878 - accuracy: 0.5641\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 9s 468ms/step - loss: 0.6846 - accuracy: 0.5641\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 9s 457ms/step - loss: 0.6870 - accuracy: 0.5641\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 0.6837 - accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 0.6863 - accuracy: 0.5641\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 0.6903 - accuracy: 0.5641\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 10s 480ms/step - loss: 0.6869 - accuracy: 0.5641\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 9s 444ms/step - loss: 0.6894 - accuracy: 0.5641\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 9s 435ms/step - loss: 0.6840 - accuracy: 0.5641\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 0.6867 - accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 0.6829 - accuracy: 0.5641\n",
      "Accuracy on test---\n",
      "0.4\n",
      "0.0\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 9s 464ms/step - loss: 1.1987 - accuracy: 0.4359\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 9s 454ms/step - loss: 0.6938 - accuracy: 0.4872\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 483ms/step - loss: 0.6969 - accuracy: 0.5385\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 9s 473ms/step - loss: 0.6923 - accuracy: 0.5641\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 9s 447ms/step - loss: 0.6923 - accuracy: 0.5641\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 9s 450ms/step - loss: 0.6918 - accuracy: 0.5641\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 0.6914 - accuracy: 0.5641\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 9s 442ms/step - loss: 0.6913 - accuracy: 0.5641\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 9s 462ms/step - loss: 0.6908 - accuracy: 0.5641\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 9s 452ms/step - loss: 0.6905 - accuracy: 0.5641\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 9s 455ms/step - loss: 0.6908 - accuracy: 0.5641\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 9s 451ms/step - loss: 0.6911 - accuracy: 0.5641\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 0.6902 - accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 9s 468ms/step - loss: 0.6893 - accuracy: 0.5641\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 9s 463ms/step - loss: 0.6890 - accuracy: 0.5641\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 9s 468ms/step - loss: 0.6913 - accuracy: 0.5641\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 0.6884 - accuracy: 0.5641\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 9s 460ms/step - loss: 0.6876 - accuracy: 0.5641\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 10s 476ms/step - loss: 0.6898 - accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 9s 465ms/step - loss: 0.6892 - accuracy: 0.5641\n",
      "Accuracy on test---\n",
      "0.4\n",
      "0.0\n",
      "Epoch 1/20\n",
      "20/20 [==============================] - 9s 468ms/step - loss: 2.3872 - accuracy: 0.4103\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 9s 456ms/step - loss: 0.6943 - accuracy: 0.5641\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 10s 478ms/step - loss: 0.6930 - accuracy: 0.5641\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 9s 468ms/step - loss: 0.6923 - accuracy: 0.5641\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 10s 475ms/step - loss: 0.6920 - accuracy: 0.5641\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 9s 469ms/step - loss: 0.6914 - accuracy: 0.5641\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 10s 476ms/step - loss: 0.6913 - accuracy: 0.5641\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 9s 469ms/step - loss: 0.6896 - accuracy: 0.5641\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 9s 466ms/step - loss: 0.6900 - accuracy: 0.5641\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 9s 466ms/step - loss: 0.6900 - accuracy: 0.5641\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 9s 453ms/step - loss: 0.6909 - accuracy: 0.5641\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 9s 456ms/step - loss: 0.6895 - accuracy: 0.5641\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 9s 470ms/step - loss: 0.6902 - accuracy: 0.5641\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 9s 463ms/step - loss: 0.6872 - accuracy: 0.5641\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 9s 463ms/step - loss: 0.6874 - accuracy: 0.5641\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 9s 454ms/step - loss: 0.6865 - accuracy: 0.5641\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 9s 458ms/step - loss: 0.6873 - accuracy: 0.5641\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 9s 466ms/step - loss: 0.6885 - accuracy: 0.5641\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 9s 454ms/step - loss: 0.6891 - accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 9s 459ms/step - loss: 0.6858 - accuracy: 0.5641\n",
      "Accuracy on test---\n",
      "0.4\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "X = X.astype('float32')\n",
    "X = X / 255.0\n",
    "# Split X, y into training and test data\n",
    "\n",
    "data_sizes = [1200, 1500, 1800, 2100]\n",
    "for size in data_sizes: \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:size], y[:size], test_size = 0.1, random_state = 42) \n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=X.shape[1:]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "      model.fit(X_train, y_train, batch_size=2, epochs=20, verbose = 1) \n",
    "\n",
    "    # Do an accuracy test on data with only ~10% interesting claseses\n",
    "    print('Accuracy on test---')\n",
    "    y_pred_test=model.predict_classes(X_test)\n",
    "    print(accuracy_score(y_test,y_pred_test))\n",
    "    print(recall_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]\n",
      "\n",
      "\n",
      " [[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]\n",
      "\n",
      "\n",
      " [[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [4.8246907e-06]\n",
      "   [9.7096899e-06]\n",
      "   [7.6591959e-06]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [0.0000000e+00]\n",
      "   [7.5988874e-06]\n",
      "   [0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [6.7545666e-06]\n",
      "   [0.0000000e+00]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [9.2272212e-06]\n",
      "   [1.5378702e-05]\n",
      "   [0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]\n",
      "\n",
      "\n",
      " [[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [6.7545666e-06]\n",
      "   [6.7545666e-06]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [0.0000000e+00]\n",
      "   [0.0000000e+00]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]\n",
      "\n",
      "\n",
      " [[[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [0.0000000e+00]\n",
      "   [3.7391351e-06]\n",
      "   [6.6942580e-06]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [6.1514802e-06]\n",
      "   [3.4979005e-06]\n",
      "   [6.2720974e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]\n",
      "\n",
      "  [[1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   ...\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]\n",
      "   [1.5378702e-05]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 300, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=16, epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
